{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzrDpZQyHRiH"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlUpKXK-HRiN"
      },
      "outputs": [],
      "source": [
        "!pip install d2l==0.16.1 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5JH4I90HRiP"
      },
      "source": [
        "# Image Augmentation\n",
        ":label:`sec_image_augmentation`\n",
        "\n",
        "\n",
        "We mentioned that large-scale datasets are prerequisites for the successful\n",
        "application of deep neural networks in\n",
        ":numref:`sec_alexnet`. Image augmentation technology expands the scale of training datasets\n",
        "by making a series of random changes to the training images to produce similar,\n",
        "but different, training examples. Another way to explain image augmentation is\n",
        "that randomly changing training examples can reduce a model's dependence on\n",
        "certain properties, thereby improving its capability for generalization. For\n",
        "example, we can crop the images in different ways, so that the objects of\n",
        "interest appear in different positions, reducing the model's dependence on the\n",
        "position where objects appear. We can also adjust the brightness, color, and\n",
        "other factors to reduce model's sensitivity to color. It can be said that image\n",
        "augmentation technology contributed greatly to the success of AlexNet. In this\n",
        "section, we will discuss this technology, which is widely used in computer\n",
        "vision.\n",
        "\n",
        "First, import the packages or modules required for the experiment in this section.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WWnNsaaHHRiP"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from d2l import torch as d2l\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EK30JnIHRiQ"
      },
      "source": [
        "## Common Image Augmentation Method\n",
        "\n",
        "In this experiment, we will use an image with a shape of $400\\times 500$ as an example.\n",
        "\n",
        "We first need to download the image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3BQ51MmIDqm"
      },
      "outputs": [],
      "source": [
        "!wget \"https://raw.githubusercontent.com/d2l-ai/d2l-en/master/img/cat1.jpg\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oXvMVdZIjYH"
      },
      "source": [
        "Now let's visualize the image that we downloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6N_CobrUHRiQ"
      },
      "outputs": [],
      "source": [
        "d2l.set_figsize()\n",
        "img = d2l.Image.open('cat1.jpg')\n",
        "d2l.plt.imshow(img);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fewlk_mTHRiT"
      },
      "source": [
        "Most image augmentation methods have a certain degree of randomness. To make it easier for us to observe the effect of image augmentation, we next define the auxiliary function `apply`. This function runs the image augmentation method `aug` multiple times on the input image `img` and shows all results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WHBTDM4rHRiT"
      },
      "outputs": [],
      "source": [
        "def apply(img, aug, num_rows=2, num_cols=4, scale=1.5):\n",
        "    Y = [aug(img) for _ in range(num_rows * num_cols)]\n",
        "    d2l.show_images(Y, num_rows, num_cols, scale=scale)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzcIoRdYHRiT"
      },
      "source": [
        "### Flipping and Cropping\n",
        "\n",
        "Flipping the image left and right usually does not change the category of the object. This is one of the earliest and most widely used methods of image augmentation. Next, we use the `transforms` module to create the `RandomFlipLeftRight` instance, which introduces a 50% chance that the image is flipped left and right.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph6qUlYZHRiT"
      },
      "outputs": [],
      "source": [
        "apply(img, torchvision.transforms.RandomHorizontalFlip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM9ZflyWHRiU"
      },
      "source": [
        "Flipping up and down is not as commonly used as flipping left and right. However, at least for this example image, flipping up and down does not hinder recognition. Next, we create a `RandomFlipTopBottom` instance for a 50% chance of flipping the image up and down.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvlsAOQMHRiV"
      },
      "outputs": [],
      "source": [
        "apply(img, torchvision.transforms.RandomVerticalFlip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vhEEv4zHRiW"
      },
      "source": [
        "In the example image we used, the cat is in the middle of the image, but this\n",
        "may not be the case for all images. In\n",
        ":numref:`sec_pooling`,\n",
        "we explained that the pooling layer can reduce the sensitivity of the\n",
        "convolutional layer to the target location. In addition, we can make objects\n",
        "appear at different positions in the image in different proportions by randomly\n",
        "cropping the image. This can also reduce the sensitivity of the model to the\n",
        "target position.\n",
        "\n",
        "In the following code, we randomly crop a region with an area of 10% to 100% of the original area, and the ratio of width to height of the region is randomly selected from between 0.5 and 2. Then, the width and height of the region are both scaled to 200 pixels. Unless otherwise stated, the random number between $a$ and $b$ in this section refers to a continuous value obtained by uniform sampling in the interval $[a, b]$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-BZIKxPHRiW"
      },
      "outputs": [],
      "source": [
        "shape_aug = torchvision.transforms.RandomResizedCrop(\n",
        "    (200, 200), scale=(0.1, 1), ratio=(0.5, 2))\n",
        "apply(img, shape_aug)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCN7LVj7JhQS"
      },
      "source": [
        "**Exercise 1:** Change the scale parameter so the crop region goes from 1% to 10% of the image. Does it makes sense? Why?\n",
        "\n",
        "**Exercise 2:** Find the optimal range to crop this image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jaEIm4fHRiX"
      },
      "source": [
        "### Changing the Color\n",
        "\n",
        "Another augmentation method is changing colors. We can change four aspects of the image color: brightness, contrast, saturation, and hue. In the example below, we randomly change the brightness of the image to a value between 50% ($1-0.5$) and 150% ($1+0.5$) of the original image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UC8Eld6DHRiX"
      },
      "outputs": [],
      "source": [
        "apply(img, torchvision.transforms.ColorJitter(\n",
        "    brightness=0.5, contrast=0, saturation=0, hue=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9mXsJOtHRiX"
      },
      "source": [
        "Similarly, we can randomly change the hue of the image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L01wpAO7HRiY"
      },
      "outputs": [],
      "source": [
        "apply(img, torchvision.transforms.ColorJitter(\n",
        "    brightness=0, contrast=0, saturation=0, hue=0.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIwY6Ex_KIIO"
      },
      "source": [
        "*Ok, have you ever seen a green cat?*\n",
        "\n",
        "**Exercise 3:** Try different hue ranges and select one that is more realistic for cats.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQBDBavaHRiZ"
      },
      "source": [
        "**Exercice 4:** We can also create a `ColorJitter` instance and set how to randomly change the `brightness`, `contrast`, `saturation`, and `hue` of the image at the same time. Do this in the following code box\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1xV4N3uHRiZ"
      },
      "outputs": [],
      "source": [
        "color_aug = torchvision.transforms.ColorJitter('''Write your code HERE''')\n",
        "apply(img, color_aug)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E9E0qlbHRiZ"
      },
      "source": [
        "### Overlying Multiple Image Augmentation Methods\n",
        "\n",
        "In practice, we will overlay multiple image augmentation methods. We can overlay the different image augmentation methods defined above and apply them to each image by using a `Compose` instance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNjyw-olHRiZ"
      },
      "outputs": [],
      "source": [
        "augs = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.RandomHorizontalFlip(), color_aug, shape_aug])\n",
        "apply(img, augs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
