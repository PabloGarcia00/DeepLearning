{"cells":[{"cell_type":"markdown","metadata":{"id":"UJsj9zLabPhG"},"source":["# Object localization with MLPs\n","Object localization is a computer-vision task that involves identifying the location of one or more objects within an image or video. The goal of object localization is to identify the precise location and size of the object(s) within an image. This is typically done by drawing a bounding box around the object, which indicates its location and extent within the image.\n","\n","Object localization is an important task in many applications, such as object detection, tracking, and recognition. It is often used in fields like autonomous driving, robotics, and surveillance, where identifying the location and motion of objects is critical for decision-making. Also in agri-food, object localization is often used to detect, for instance, a fruit in an image for robotic harvesting, or a cow in a video frame to measure the distance that she walked.\n","\n","\n","\n","<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F999C58335BA4941F0F&f=1&nofb=1&ipt=ccd6041b1f8ce1fe478ea771aa1b9bd412286cf9ea3342a3221c37ec87379612&ipo=images\" width=800>\n","\n","The image above displays the difference between classification, object localizacion, object detection, and object instance segmentation. For object localization, the method needs to detect one object in the image and predict the bounding box. \n","\n","A bounding box is defined by four coordinates: \n","* two coordinates for the postion\n","* one for the width, and \n","* one for the height.\n","\n","Object localization can be done using a variety of techniques, such as template matching, feature-based methods, deep learning, and other machine-learning approaches. In this practical, you'll implement a MLP that performs object localization of ellipses in images.\n","\n","Let's start with the required imports."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g-P8m0cbbZZx"},"outputs":[],"source":["!pip install d2l==0.16 --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2onbBuK8bPhL"},"outputs":[],"source":["# General imports\n","from PIL import Image, ImageDraw\n","import random\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.axes_grid1 import ImageGrid\n","\n","# Deep learning imports\n","from d2l import torch as d2l\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset\n","from torchvision.transforms.functional import to_tensor, to_pil_image\n"]},{"cell_type":"markdown","metadata":{"id":"BksGnajjbPhO"},"source":["## Generating images with ellipses\n","In this notebook, we will work with some synthetic images containing. We will start with a relatively simple situations where the task is to locate a red ellipse on a black background. We will then make it more challenging by adding variation to the colors of the foreground and the background. In later tutorials, you will learn more advanced neural network architectures that allow you to locate real objects in real images.\n","\n","The next cell contains a function to generate images with ellipses on it, and some helper functions that you'll need for visualization purposes. \n","\n","**Exercise:**\n","* Study the code briefly to understand what the functions do\n","* Run the code to load the functions.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bRgBah_nbPhP"},"outputs":[],"source":["def draw_random_ellipse(width, height, color_ellipse, color_background=\"black\"):\n","    \"\"\"\n","    This function draws a random ellipse on an image with the given width and height.\n","    The ellipse has a random size and position, and is filled with the specified color.\n","    The background of the image can also be specified, defaulting to black.\n","    Returns the resulting image, ellipse center coordinates, and ellipse width and height.\n","\n","    Parameters:\n","        - width (int): the width of the image in pixels\n","        - height (int): the height of the image in pixels\n","        - color_ellipse (tuple[int]): the color of the ellipse in the format '(red, green, blue)'\n","        - color_background (str or tuple[int]): the color of the background in the format '(red, green, blue)' or string.\n","            Default: 'black'\n","\n","    Returns:\n","        A tuple containing:\n","        - img (PIL.Image): the resulting image\n","        - x (int): the x coordinate of the center of the ellipse\n","        - y (int): the y coordinate of the center of the ellipse\n","        - w (int): the width of the ellipse\n","        - h (int): the height of the ellipse\n","    \"\"\"\n","    # Create image\n","    img = Image.new(\"RGB\", (width, height), color=color_background)\n","\n","    # Create a drawing context\n","    draw = ImageDraw.Draw(img)\n","\n","    # Calculate minimum ellipse size\n","    min_rx = width // 12\n","    min_ry = height // 12\n","\n","    # Calculate maximum ellipse size\n","    max_rx = width // 6\n","    max_ry = height // 6\n","    # Generate random ellipse parameters within maximum size\n","    rx = random.randint(min_rx, max_rx)\n","    ry = random.randint(min_rx, max_ry)\n","    x = random.randint(rx, width - rx)\n","    y = random.randint(ry, height - ry)\n","\n","    # Draw ellipse onto image\n","    draw.ellipse((x - rx, y - ry, x + rx, y + ry), fill=color_ellipse)\n","\n","    return img, x, y, 2 * rx, 2 * ry\n","\n","def plot_bbox(img, x, y, w, h, color=\"blue\"):\n","    \"\"\"\n","    This function plots a bounding box on the given image.\n","    The bounding box is defined by its center coordinates (x, y) and its width and height (w, h).\n","    The bounding box is drawn in blue with a width of 3 pixels.\n","    Returns the resulting image.\n","\n","    Parameters:\n","        - img (PIL.Image): the image to plot the bounding box on\n","        - x (int): the x coordinate of the center of the bounding box\n","        - y (int): the y coordinate of the center of the bounding box\n","        - w (int): the width of the bounding box\n","        - h (int): the height of the bounding box\n","\n","    Returns:\n","        A PIL.Image object representing the original image with the bounding box plotted on it.\n","    \"\"\"\n","    draw = ImageDraw.Draw(img)\n","    draw.rectangle(\n","        (x - w / 2, y - h / 2, x + w / 2, y + h / 2),\n","        outline=color,\n","        width=2,\n","    )\n","    return img\n","\n","\n","def plot_grid(imgs, nrows, ncols):\n","    \"\"\"\n","    This function plots a grid of images using the given list of images.\n","    The grid has the specified number of rows and columns.\n","    The size of the figure is set to 10x10 inches.\n","    Returns None.\n","\n","    Parameters:\n","        - imgs (List[PIL.Image]): a list of PIL.Image objects to plot\n","        - nrows (int): the number of rows in the grid\n","        - ncols (int): the number of columns in the grid\n","\n","    Returns:\n","        None.\n","    \"\"\"\n","    assert len(imgs) == nrows * ncols, f\"nrows*ncols must be equal to the number of images\"\n","    fig = plt.figure(figsize=(10.0, 10.0))\n","    grid = ImageGrid(\n","        fig,\n","        111,  # similar to subplot(111)\n","        nrows_ncols=(nrows, ncols),\n","        axes_pad=0.1,  # pad between axes in inch.\n","    )\n","    for ax, im in zip(grid, imgs):\n","        # Iterating over the grid returns the Axes.\n","        ax.imshow(im)\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"Da7II67teqUk"},"source":["Let's test the function by letting it create ten images with random ellipses, at random locations and with random sizes. \n","\n","**Exercise:**\n","* Run the code\n","* You see ten image and another ten images with the bounding box\n","* Think what the input and what the output will be of the MLP that we are going to define"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"toRUrMGbbPhR"},"outputs":[],"source":["# Let's test our functions\n","img_size = 100\n","display_imgs = []\n","display_imgs_bbox = []\n","\n","for i in range(10):\n","    img, x, y, w, h = draw_random_ellipse(width=img_size, height=img_size, color_ellipse=(255, 0, 0))\n","    display_imgs.append(img.copy())\n","    img = plot_bbox(img, x, y, w, h)\n","    display_imgs_bbox.append(img)\n","plot_grid(imgs=display_imgs, nrows=2, ncols=5)\n","plot_grid(imgs=display_imgs_bbox, nrows=2, ncols=5)\n"]},{"cell_type":"markdown","metadata":{"id":"5iIWqKDwoIBf"},"source":["\n","**Exercise:**\n","* Run the code below and inspect the shape of the image. \n","* Calculate how many values this image contains, Consider that an image has `img_size*img_size` pixels and each pixel has 3 channels (red, green, blue)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ga3UYZwboIgY"},"outputs":[],"source":["import numpy as np \n","img, x, y, w, h = draw_random_ellipse(width=img_size, height=img_size, color_ellipse=(255, 0, 0))\n","np.array(img).shape"]},{"cell_type":"markdown","metadata":{"id":"optkXxkrbPhS"},"source":["## The Dataset class\n","The PyTorch **Dataset** class can be used to define a custom dataset for use with PyTorch's DataLoader, which allows for efficient loading and batching of data.\n","\n","In PyTorch, a dataset is represented by a subclass of the Dataset class. Each dataset subclass must implement three methods:\n","- `__init__(self, ...)`:\n","This method is the constructor of the dataset class. It initializes the dataset with any necessary information such as file paths, labels, etc. It can also perform some pre-processing steps, such as loading the data into memory or computing statistics of the data. \n","\n","- `__getitem__(self, index)`:\n","This method is used to retrieve an individual sample from the dataset at the given index. It takes an index as input and returns the corresponding data sample and its label (or other metadata). This method is what enables us to use PyTorch's DataLoader to iterate through the dataset and retrieve batches of data.\n","\n","- `__len__(self)`:\n","It returns the total number of samples in the dataset. This method is used by the DataLoader to determine the length of the dataset and to split the data into batches.\n","\n","By defining a custom Dataset class, you can easily create a data pipeline that loads, transforms, and feeds your data into a machine-learning model. The DataLoader class then allows you to efficiently load and batch the data for training or inference. Overall, the Dataset class is an essential building block for creating efficient, scalable, and customizable data pipelines in PyTorch. You **MUST** learn how to build a dataset class for a given application.\n","\n","**Exercise:** \n","* Complete the dataset class. Hints:\n","  * In  `__init__`, you should set the class attributes `self.number_imgs` and `self.img_size`\n","  * In  `__len__`, you need to return the length of the dataset, which is provided in the init function.\n","  * In `__getitem__`, you need to use the function `draw_random_ellipse()` to get a random image and the x, y, width and height of the bounding box.\n","  * In `__getitem__`, you need to set the data by making a tensor of the image\n","  * In `__getitem__`, you need to define the label for the image, should be a tensor storing the four bounding box coordinates **normalized with respect to the image size** using:\n","  ```torch.tensor([x, y, w, h]) / self.img_size```\n","\n","* Mind that the class for the dataset is called `EllipseDataset`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"__6l3q3BbPhT"},"outputs":[],"source":["class EllipseDataset(Dataset):\n","    \"\"\"\n","    This PyTorch dataset generates a set of images containing a random ellipse with a corresponding label.\n","    The dataset generates a specified number of images with the given size.\n","\n","    Attributes:\n","        - number_imgs (int): the number of images to generate\n","        - img_size (int): the size of each image in pixels\n","    \"\"\"\n","\n","    def __init__(self, number_imgs, img_size):\n","        \"\"\"\n","        Constructs a new EllipseDataset object.\n","\n","        Parameters:\n","            - number_imgs (int): the number of images to generate\n","            - img_size (int): the size of each image in pixels\n","        \"\"\"\n","        # TODO: save the method inputs into parameters of the class so they can be used by other methods (2 lines)\n","        ..\n","\n","    def __len__(self):\n","        \"\"\"\n","        Returns the number of images in the dataset.\n","\n","        Returns:\n","            An integer representing the number of images in the dataset.\n","        \"\"\"\n","        # TODO: return the size of the dataset (Hint: is set using the constructor function)\n","        ..\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        Generates a random ellipse image with a corresponding label (=bounding box).\n","\n","        Parameters:\n","            - idx (int): the index of the image to generate. Not used in this case as we generate image randomly.\n","\n","        Returns:\n","            A tuple containing:\n","            - data (Tensor): a tensor representing the image data\n","            - label (Tensor): a tensor representing the label data: [x, y, w, h] relative to the image size\n","        \"\"\"\n","        # TODO: create an image with an ellipse using the provided function. Keep the color of the ellipse as red (255, 0, 0)\n","        # NOTE: the label (or bounding box) should be normalized using the image size so the values range from 0 to 1\n","        img, x, y, w, h = ..\n","\n","        data = to_tensor(img)\n","        label = ..\n","        return data, label\n"]},{"cell_type":"markdown","metadata":{"id":"WiYKiQ8qbPhU"},"source":["## Losses and performance metrics on regression networks\n","The main differences between training a regression task and classification task are the loss function used and the performance metrics. Apart from it, the rest of the training loop should be practically identical in Pytorch. A common loss and performance metric for regression is Mean Squared Error (MSE). And a common metric for evaluation of regression tasks is the Pearson correlation coefficient:\n","\n","- **Mean Squared Error (MSE)** is a popular loss function used in regression. It measures the average of the squared differences between the predicted and actual values of the target variable. In other words, it calculates the average of the squared errors. A lower MSE value indicates better performance of the model in predicting the target variable.\n","\n","- **Pearson correlation coefficient** is a performance metric commonly used in regression to evaluate the strength and direction of the linear relationship between the predicted values and the actual values of the target variable. The Pearson correlation coefficient, also known as Pearson's r, measures the degree of linear correlation between two variables, where a value of +1 indicates a perfect positive linear correlation, a value of 0 indicates no linear correlation, and a value of -1 indicates a perfect negative linear correlation. In regression tasks, a high Pearson correlation coefficient indicates that the model is effectively capturing the relationship between the input features and the target variable.\n","\n","Run the code below to load function definitions to implement the MSE and Pearson correlation, and to evaluate the accuracy using these two metrics."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_G5LZWv7bPhW"},"outputs":[],"source":["def pearson_correlation(x1, x2, eps=1e-8):\n","    \"\"\"\n","    Calculates the Pearson correlation coefficient between two 1D tensors.\n","\n","    Args:\n","        x1 (torch.Tensor): First input tensor (1D).\n","        x2 (torch.Tensor): Second input tensor (1D, with size matching x1).\n","        eps (float, optional): A small value added to the denominator to avoid division by zero. Default: 1e-8.\n","\n","    Example:\n","        >>> input1 = torch.randn(128)\n","        >>> input2 = torch.randn(128)\n","        >>> output = pearson_correlation(input1, input2)\n","        >>> print(output)\n","\n","    Returns:\n","        A tensor containing the Pearson correlation coefficient between x1 and x2.\n","    \"\"\"\n","    assert x1.dim() == 1, \"Input must be 1D matrix / vector.\"\n","    assert x1.size() == x2.size(), \"Input sizes must be equal.\"\n","    x1_bar = x1 - x1.mean()\n","    x2_bar = x2 - x2.mean()\n","    dot_prod = x1_bar.dot(x2_bar)\n","    norm_prod = x1_bar.norm(2) * x2_bar.norm(2)\n","    return dot_prod / norm_prod.clamp(min=eps)\n","\n","\n","def MSE(y_hat, y):\n","    \"\"\"\n","    Calculates the Mean Squared Error (MSE) between two 1D tensors.\n","\n","    Args:\n","        y_hat (torch.Tensor): Predictions tensor (1D).\n","        y (torch.Tensor): Ground truth tensor (1D, with size matching y_hat).\n","\n","    Example:\n","        >>> y_hat = torch.randn(128)\n","        >>> y = torch.randn(128)\n","        >>> output = MSE(y_hat, y)\n","        >>> print(output)\n","\n","    Returns:\n","        A tensor containing the Mean Squared Error (MSE) between y_hat and y.\n","    \"\"\"\n","    return torch.square(y - y_hat).mean()\n","\n","\n","def evaluate_accuracy(net, data_iter):\n","    \"\"\"\n","    Evaluates the accuracy of a network on a given dataset.\n","\n","    Args:\n","        net (nn.Module): The network to evaluate.\n","        data_iter (DataLoader): The DataLoader representing the dataset to evaluate.\n","\n","    Returns:\n","        A tuple containing the Pearson correlation coefficient and the Mean Squared Error (MSE)\n","        between the network predictions and the ground truth targets on the dataset.\n","    \"\"\"\n","    metric = d2l.Accumulator(3)  # pearson, loss, 1\n","    for X, y in data_iter:\n","        y_hat = net(X).flatten()\n","        y = y.flatten()\n","        metric.add(pearson_correlation(y_hat, y), MSE(y_hat, y), 1)\n","    return metric[0] / metric[2], metric[1] / metric[2]\n"]},{"cell_type":"markdown","metadata":{"id":"1SGX0JVbbPhW"},"source":["## Training loop for bounding-box regression\n","As mentione above, apart from the loss and performance metrics, very few things change in the regression training loop. Therefore, you should be able to fill the gaps in the following code cell.\n","\n","**Exercise:**\n","* Fill in the gaps in the code to\n","  * Use the network to predict the output `y_hat` based on the input `X`.\n","  * Calculate the loss with the loss function by comparing the predicted and true output (`y`)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4xWeygbZbPhY"},"outputs":[],"source":["def train_epoch_regression(net, train_iter, loss, updater):\n","    \"\"\"Similar training loop to the one defined in Chapter 3.\"\"\"\n","    # Set the model to training mode\n","    if isinstance(net, torch.nn.Module):\n","        net.train()\n","    # Sum of training loss, sum of training accuracy, no. of examples\n","    metric = d2l.Accumulator(4)\n","    for X, y in train_iter:\n","        # TODO: Use the network to predict the output y_hat for the given input X\n","        y_hat = ..\n","        # TODO: calculate the los from the predicted and true y values\n","        l = loss(..,  ..)\n","\n","        # Compute gradients and update parameters\n","        updater.zero_grad()\n","        l.backward()\n","        updater.step()\n","\n","        # Log evaluation metrics: Sum of training loss, sum of training accuracy, no. of examples\n","        metric.add(float(l), pearson_correlation(y_hat.flatten(), y.flatten()), y.size().numel(), 1)\n","\n","    # Return training loss and training accuracy\n","    return metric[0] / metric[2], metric[1] / metric[3]\n","\n","\n","def train_regression(net, train_iter, test_iter, loss, num_epochs, updater):\n","    \"\"\"Train a model (similar to the one defined in Chapter 3).\"\"\"\n","    animator = d2l.Animator(\n","        xlabel=\"epoch\", xlim=[1, num_epochs], ylim=[0, 1], legend=[\"train loss\", \"train acc\", \"test acc\", \"test loss\"]\n","    )\n","    for epoch in range(num_epochs):\n","        # Run one training epoch\n","        train_metrics = train_epoch_regression(net, train_iter, loss, updater)\n","        # Evaluate the network\n","        test_acc, test_loss = evaluate_accuracy(net, test_iter)\n","        # Show the performance of the network during training\n","        animator.add(epoch + 1, train_metrics + (test_acc, test_loss))\n","        \n","    train_loss, train_acc = train_metrics\n"]},{"cell_type":"markdown","metadata":{"id":"xrkZjDkXbPhY"},"source":["## Training parameters\n","**Exercise:** You need to define the following parameters before starting to train:\n","1. Loss: use `nn.MSELoss()` ([documentation](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html))\n","2. Define the train and test dataset using the earlier defined class `EllipseDataset`. Use 1000 images in the training set and 500 in the test set, with the img_size set to `img_size`.\n","3. Some code is already defined for you to create the dataloaders based on the dataset. Check the code to see how this is done.\n","4. Your network. Define the MLP as follows:\n","  * First a flatten layer to flatten the 2D image into a 1D vector. \n","    * Calculate the length of this input vector. Consider that the image has `img_size*img_size` pixels and each pixel has 3 channels (red, green, blue).\n","  * A hidden (fully connected) layer with 256 hidden neurons and using ReLU activation \n","  * An output layer with 4 output neurons (for the four bounding box coordinates)\n","5. Your trainer (also called optimizer) using `torch.optim.SGD(net.parameters(), lr=lr)`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sXZUHLTxbPhZ"},"outputs":[],"source":["# Defining some parameters\n","batch_size, lr = 16, 0.025\n","img_size = 100\n","\n","# Loss\n","### TODO: 1. ADD YOUR CODE HERE (1 line)\n","loss = ..\n","\n","# Let's load the dataset and create dataloaders\n","### TODO: 2. ADD YOUR CODE HERE TO LOAD THE DATASETS (~4 lines)\n","train_dataset = .. \n","test_dataset = ..\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","# Let's define the architecture of our MLP\n","### TODO: 4. CREATE YOUR MLP\n","net = ..\n","\n","# Initialize the network with small random weights\n","def init_weights(m):\n","    if type(m) == nn.Linear:\n","        nn.init.normal_(m.weight, std=0.02)\n","\n","\n","net.apply(init_weights)\n","\n","\n","# Define trainer (or optimizer)\n","### TODO: 5. ADD YOUR CODE HERE (1 line)\n","trainer = .."]},{"cell_type":"markdown","metadata":{"id":"93aOVvGEbPhZ"},"source":["## Training\n","Now we can start training our algorithm. Run the next cell to start training your MLP."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lkZXPIHZbPhZ"},"outputs":[],"source":["# Train\n","num_epochs = 50\n","train_regression(net, train_loader, test_loader, loss, num_epochs, trainer)\n"]},{"cell_type":"markdown","metadata":{"id":"MSUoIBAObPhZ"},"source":["## Visualization of results\n","\n","Now that we have trained the network, we can use it to predict the bounding-box coordinates of an image in the test set.\n","\n","* Some steps we need to take:\n","  * We sample an image from the testset\n","  * Our network is adapted to take batches of images, which correspods to an array of the dimensions `[batch_size, 3, img_size, img_size]`. Therefore, if we want to feed our image with dimensions `[3, img_size, img_size]` to our network, we need to expand its dimensions like this:\n","`img = img.unsqueeze(0)` to create a batch with one image\n","  * We use the trained network to predict the bbox coordinates for the image\n","  * As the network returns a tensor with bbox coordinates for all images in the batch, and since we have a batch of one image, we need to get the idx 0 of the output of the network\n","  * Remember that the bbox coordinate that we put in the training data are relative to the size of the image, so we have to upscale the predicted coordinates to match the size of the image.\n","* Study the code below to identify these steps\n","* Run the code to see a prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4A2mk7QusLpF"},"outputs":[],"source":["test_img_id = 10\n","test_data = test_dataset[test_img_id]\n","test_img = test_data[0]\n","test_img_input = test_img.unsqueeze(0)\n","pred = net(test_img_input)            \n","pred = pred[0]\n","pred = pred * img_size\n","print('Predicted bounding-box coordinates:', pred)\n","\n","# Show the image and the predicted bounding box\n","img_show = to_pil_image(test_img) \n","img = plot_bbox(img_show, pred[0], pred[1], pred[2], pred[3])\n","img_show"]},{"cell_type":"markdown","metadata":{"id":"3sspoEossPeb"},"source":["**Exercise:**\n","* Use the code above to finish the code cell below, so that it plots the results for multiple test images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uEPyygChbPhb"},"outputs":[],"source":["# Setting our network to eval mode\n","net.eval()\n","\n","# Let's select 10 images and pass them through our network\n","test_imgs = [test_dataset[idx][0] for idx in range(10)]\n","display_imgs = []\n","for test_img in test_imgs:\n","    # TODO: unsqueeze the test image, run it through the network\n","    #       and the predicted bbox coordinates \n","\n","    # Draw the bounding box in the image for visualization\n","    img_show = to_pil_image(test_img) # Convert img from tensor to PIL image format\n","    img_show = plot_bbox(img_show, pred[0], pred[1], pred[2], pred[3])\n","    display_imgs.append(img_show)\n","\n","# Plot the results\n","plot_grid(imgs=display_imgs, nrows=2, ncols=5)\n"]},{"cell_type":"markdown","metadata":{"id":"OIJEaNGbbPhc"},"source":["## Making our dataset more challenging\n","Until now, we've been using only red ellipses over a black background. Let's make things more challenging by having random ellipse colors. You can use the following line to define a random RGB color:\n","```python\n","color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n","```\n","\n","**Exercise:**\n","* Change the code in `__getitem__` to now create ellipses with random colors\n","* Train and test a new network on this data by completing the three code cells below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tFGK9KeUbPhd"},"outputs":[],"source":["class EllipseDataset(Dataset):\n","    \"\"\"\n","    This PyTorch dataset generates a set of images containing a random ellipse with a corresponding label.\n","    The dataset generates a specified number of images with the given size.\n","\n","    Attributes:\n","        - number_imgs (int): the number of images to generate\n","        - img_size (int): the size of each image in pixels\n","    \"\"\"\n","\n","    def __init__(self, number_imgs, img_size):\n","        \"\"\"\n","        Constructs a new EllipseDataset object.\n","\n","        Parameters:\n","            - number_imgs (int): the number of images to generate\n","            - img_size (int): the size of each image in pixels\n","        \"\"\"\n","        self.number_imgs = number_imgs\n","        self.img_size = img_size\n","\n","\n","    def __len__(self):\n","        \"\"\"\n","        Returns the number of images in the dataset.\n","\n","        Returns:\n","            An integer representing the number of images in the dataset.\n","        \"\"\"\n","        return self.number_imgs\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        Generates a random image with a corresponding label.\n","\n","        Parameters:\n","            - idx (int): the index of the image to generate. Not used in this case as we generate image randomly.\n","\n","        Returns:\n","            A tuple containing:\n","            - data (Tensor): a tensor representing the image data\n","            - label (Tensor): a tensor representing the label data\n","        \"\"\"\n","        # TODO: create an image with an ellipse with random colors using the provided function.\n","\n","\n","        data = to_tensor(img)\n","        return data, label\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Khpim8K9bPhd"},"outputs":[],"source":["# Defining some parameters\n","batch_size, lr, num_epochs = 16, 0.025, 50\n","img_size = 100\n","\n","# Loss\n","### TODO: ADD YOUR CODE HERE (1 line)\n","\n","\n","# Let's load the dataset and create dataloaders\n","### TODO: ADD YOUR CODE HERE (~4 lines)\n","\n","# Let's define the architecture of our MLP\n","### TODO: CREATE YOUR MLP\n","\n","\n","def init_weights(m):\n","    if type(m) == nn.Linear:\n","        nn.init.normal_(m.weight, std=0.02)\n","\n","\n","net.apply(init_weights)\n","\n","\n","# Define trainer (or optimizer)\n","### TODO: ADD YOUR CODE HERE (1 line)\n","\n","\n","# Train\n","train_regression(net, train_loader, test_loader, loss, num_epochs, trainer)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"frx2vk8fbPhe"},"outputs":[],"source":["# Setting our network to eval mode\n","net.eval()\n","\n","# Let's select 10 images and pass them through our network\n","imgs = [test_dataset[idx][0] for idx in range(10)]\n","display_imgs = []\n","for img in imgs:\n","    ### TODO: pass the image through the network and scale the predicted bounding box according to the image size (~3 lines)\n","\n","\n","    # Convert img from tensor to PIL image format\n","    img = to_pil_image(img)\n","\n","    # TODO: plot the bounding box into the image using the provided function in this notebook (~1 line)\n","\n","\n","    # Add image to list\n","    display_imgs.append(img)\n","\n","# Plot the results\n","plot_grid(imgs=display_imgs, nrows=2, ncols=5)\n"]},{"cell_type":"markdown","metadata":{"id":"fQMr6Id4bPhf"},"source":["## Even more challenging: random background color\n","\n","You see that with the random color of the ellipse, the MLP can still predict the location to some extend, although the accuracy became lower. Let's now make it even more complex by adding also a random color of the background.\n","\n","**Exercise:** \n","* Change the dataset class so now the color of the background is random as well. You can do so by using the parameter `color_background` in the function `draw_random_ellipse`.\n","```\n","draw_random_ellipse(..., color_ellipse=color_ellipse,color_background=color_background)\n","```\n","* Train the same network from scratch for 50 epochs. \n","* Evaluate the results. Look also on how the loss and accuracy develop over the epochs during training. Would it help to train for more epochs?\n","* Try a more complex MLP network architecture. Does that improve results? "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5iXkbF9BbPhf"},"outputs":[],"source":["# TODO: Add now also a random color to the background. \n","#       Train the network again from scratch, and\n","#       Evaluate the results.\n","\n"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"dl_course","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"f8f1e8c1b472ee82e55e97c487054a5ceffb43f99f414279b9ff201447c6d492"}}},"nbformat":4,"nbformat_minor":0}
